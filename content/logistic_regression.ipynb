{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistische Regression**\n",
    "\n",
    "Dieses Notebook behandelt die **logistische Regression** anhand eines einfachen Beispiels:\n",
    "\n",
    "1. Was ist der Unterschied zu linearer Regression?\n",
    "2. K√ºnstliche Daten: `Lernzeit ‚Üí Pr√ºfung bestanden (ja/nein)`\n",
    "3. Wie kann der Computer eine **Kurve** finden, die die Wahrscheinlichkeit f√ºrs Bestehen beschreibt?\n",
    "4. Interaktive Grafiken:\n",
    "   - Ab wie vielen Stunden w√ºrdest **du** ‚Äûbestanden‚Äú sagen?\n",
    "   - Wie sieht die **Wahrscheinlichkeit** f√ºrs Bestehen aus?\n",
    "5. Aufgaben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken laden\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# In einem Jupyter-/Colab-Notebook sorgt das daf√ºr,\n",
    "# dass die Grafiken direkt unter der Zelle angezeigt werden.\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486f71c",
   "metadata": {},
   "source": [
    "## 1. K√ºnstliche Beispieldaten erzeugen\n",
    "\n",
    "Wir betrachten wieder eine Pr√ºfung.\n",
    "\n",
    "- **x-Achse**: Lernzeit in Stunden (0 bis 5 Stunden)\n",
    "- **y-Wert**: Hat die Person bestanden?\n",
    "\n",
    "Wir vereinfachen:\n",
    "- `y = 1` ‚Üí Pr√ºfung **bestanden**\n",
    "- `y = 0` ‚Üí Pr√ºfung **nicht bestanden**\n",
    "\n",
    "Je mehr man lernt, desto **gr√∂sser** soll die Wahrscheinlichkeit f√ºrs Bestehen werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuf√§llige, aber reproduzierbare Daten erzeugen\n",
    "np.random.seed(42)\n",
    "\n",
    "# Lernzeit in Stunden\n",
    "X = np.linspace(0, 5, 30)  # 30 Werte von 0 bis 5 Stunden\n",
    "X_2d = X.reshape(-1, 1)\n",
    "\n",
    "# \"versteckte\" wahre Beziehung:\n",
    "# Bei 0 Stunden sehr kleine Chance, bei 5 Stunden sehr hohe Chance.\n",
    "# Wir bauen uns eine S-Kurve (Sigmoid) im Hintergrund.\n",
    "true_slope = 2.0       # wie stark beeinflussen Stunden die Chance zu bestehen?\n",
    "true_intercept = -4.0  # verschiebt die Kurve nach links/rechts\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Wahrscheinlichkeiten f√ºrs Bestehen\n",
    "p_pass = sigmoid(true_slope * X + true_intercept)\n",
    "\n",
    "# Jetzt w√ºrfeln wir f√ºr jede Person, ob sie besteht (1) oder nicht (0)\n",
    "y = np.random.binomial(1, p_pass)\n",
    "\n",
    "# F√ºr die Visualisierung geben wir den Punkten leichte vertikale \"Jitter\"\n",
    "y_plot = y + np.random.normal(0, 0.03, size=y.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X[y==0], y_plot[y==0], color=\"red\", label=\"nicht bestanden (0)\")\n",
    "plt.scatter(X[y==1], y_plot[y==1], color=\"green\", label=\"bestanden (1)\")\n",
    "plt.yticks([0, 1])\n",
    "plt.xlabel(\"Lernzeit in Stunden\")\n",
    "plt.ylabel(\"Pr√ºfung bestanden?\")\n",
    "plt.title(\"Beispieldaten: Lernzeit vs. bestanden (0/1)\")\n",
    "plt.grid(True, axis=\"x\")\n",
    "plt.legend()\n",
    "plt.ylim(-0.3, 1.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc8dd3",
   "metadata": {},
   "source": [
    "## 2. Idee der logistischen Regression\n",
    "\n",
    "Bei der **linearen Regression** haben wir eine **Gerade** gesucht:  \n",
    "> `y = m ¬∑ x + b`\n",
    "\n",
    "Bei einer Ja/Nein-Frage (bestanden / nicht bestanden) w√§re eine solche Gerade **ungeeignet**, denn:\n",
    "\n",
    "- Werte k√∂nnen unter 0 oder √ºber 1 gehen\n",
    "- Wir brauchen etwas wie eine **Wahrscheinlichkeit** f√ºr das Bestehen (zwischen 0 und 1)\n",
    "\n",
    "Die logistische Regression macht genau das:\n",
    "\n",
    "> Sie sagt zu jedem x (z. B. *3 Stunden Lernen*)  \n",
    "> **‚ÄûWie gross ist die Wahrscheinlichkeit, dass die Person besteht?‚Äú**\n",
    "\n",
    "Die Form ist eine **S-Kurve (Sigmoid)**:\n",
    "\n",
    "- links: Wahrscheinlichkeit nahe 0 (fast sicher nicht bestanden)\n",
    "- in der Mitte: √úbergangsbereich\n",
    "- rechts: Wahrscheinlichkeit nahe 1 (fast sicher bestanden)\n",
    "\n",
    "Der Computer sucht wieder zwei Zahlen (√§hnlich wie m und b), aber wir verstecken die komplizierte Formel und benutzen `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell f√ºr logistische Regression trainieren\n",
    "modell_log = LogisticRegression()\n",
    "modell_log.fit(X_2d, y)\n",
    "\n",
    "m_schaetzung = modell_log.coef_[0][0]   # \"Steigung\" im inneren linearen Teil\n",
    "b_schaetzung = modell_log.intercept_[0] # \"Achsenabschnitt\" im inneren linearen Teil\n",
    "\n",
    "print(\"Gesch√§tzte Parameter (intern im Modell):\")\n",
    "print(\"  Steigung m ~\", round(m_schaetzung, 3))\n",
    "print(\"  Achsenabschnitt b ~\", round(b_schaetzung, 3))\n",
    "\n",
    "# Vorhersagewahrscheinlichkeiten auf einem feineren Gitter\n",
    "X_fein = np.linspace(0, 5, 200).reshape(-1, 1)\n",
    "p_vorhersage = modell_log.predict_proba(X_fein)[:, 1]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Datenpunkte (0/1)\n",
    "plt.scatter(X[y==0], y_plot[y==0], color=\"red\", label=\"nicht bestanden (0)\")\n",
    "plt.scatter(X[y==1], y_plot[y==1], color=\"green\", label=\"bestanden (1)\")\n",
    "\n",
    "# Wahrscheinlichkeitskurve\n",
    "plt.plot(X_fein, p_vorhersage, label=\"gesch√§tzte Wahrscheinlichkeit zu bestehen\", linewidth=2)\n",
    "\n",
    "plt.yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "plt.xlabel(\"Lernzeit in Stunden\")\n",
    "plt.ylabel(\"Wahrscheinlichkeit / beobachtet (0/1)\")\n",
    "plt.title(\"Logistische Regression: Lernzeit ‚Üí p(bestanden)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.ylim(-0.3, 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6885c",
   "metadata": {},
   "source": [
    "## 3. Interaktive Ansicht: ‚ÄûAb wie vielen Stunden gilt: bestanden?‚Äú\n",
    "\n",
    "Stell dir vor, du bist Lehrer:in und du entscheidest:\n",
    "\n",
    "> ‚ÄûWer **mindestens X Stunden** lernt, besteht.‚Äú\n",
    "\n",
    "Wir stellen diese Entscheidungsgrenze als **vertikale Linie** dar.  \n",
    "Du kannst mit einem Schieberegler einstellen, ab wie vielen Stunden **du** ‚Äûbestanden‚Äú sagen w√ºrdest und siehst:\n",
    "\n",
    "- Welche Punkte w√§ren nach deiner Regel **bestanden**?\n",
    "- Welche **Fehler** machst du (z. B. jemand hat wenig gelernt, aber bestanden oder umgekehrt)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold(grenze_stunden=2.5):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    # Farben nach tats√§chlichem Ergebnis\n",
    "    colors = [\"green\" if yi == 1 else \"red\" for yi in y]\n",
    "    labels = {0: \"nicht bestanden (0)\", 1: \"bestanden (1)\"}\n",
    "    \n",
    "    # Jitter f√ºr h√ºbschere Darstellung\n",
    "    plt.scatter(X, y_plot, c=colors)\n",
    "    \n",
    "    # Vertikale Entscheidungsgrenze\n",
    "    plt.axvline(grenze_stunden, color=\"black\", linestyle=\"--\",\n",
    "                label=f\"Deine Grenze: ab {grenze_stunden:.2f} h = bestanden\")\n",
    "    \n",
    "    # Deine Entscheidung nach Schwelle\n",
    "    y_hat = (X >= grenze_stunden).astype(int)\n",
    "    \n",
    "    # Fehler z√§hlen\n",
    "    richtig = np.sum(y_hat == y)\n",
    "    gesamt = len(y)\n",
    "    genauigkeit = richtig / gesamt * 100\n",
    "    \n",
    "    plt.yticks([0, 1])\n",
    "    plt.xlabel(\"Lernzeit in Stunden\")\n",
    "    plt.ylabel(\"Pr√ºfung bestanden?\")\n",
    "    plt.title(\"Deine einfache Entscheidungsregel\")\n",
    "    plt.grid(True, axis=\"x\")\n",
    "    plt.ylim(-0.3, 1.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mit deiner Grenze bei {grenze_stunden:.2f} Stunden:\")\n",
    "    print(f\" - Richtig klassifizierte Personen: {richtig} von {gesamt}\")\n",
    "    print(f\" - Genauigkeit: {genauigkeit:.1f} %\")\n",
    "    print(\"Hinweis: Das ist eine einfache Schwellen-Regel ‚Äì noch keine Statistik üòä\")\n",
    "\n",
    "interact(\n",
    "    plot_threshold,\n",
    "    grenze_stunden=FloatSlider(value=2.5, min=0.0, max=5.0, step=0.1, description=\"Grenze (h)\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7249f",
   "metadata": {},
   "source": [
    "## 4. Interaktive Ansicht: Wahrscheinlichkeiten der logistischen Regression\n",
    "\n",
    "Jetzt schauen wir auf das **gelerntes Modell** (die S-Kurve).\n",
    "\n",
    "Du kannst eine Lernzeit ausw√§hlen und siehst:\n",
    "\n",
    "- die **Wahrscheinlichkeit**, die das Modell f√ºrs Bestehen sch√§tzt\n",
    "- eine horizontale Linie bei **50 %** ‚Üí ab dort sagt das Modell: *‚ÄûIch tippe auf bestanden.‚Äú*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logistic_with_point(stunden=2.5):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    # Wahrscheinlichkeitskurve\n",
    "    plt.plot(X_fein, p_vorhersage, linewidth=2, label=\"p(bestanden) laut Modell\")\n",
    "    \n",
    "    # horizontale Linie bei 0.5\n",
    "    plt.axhline(0.5, color=\"gray\", linestyle=\"--\", label=\"Grenze 0.5 (50%)\")\n",
    "    \n",
    "    # gew√§hlte Stunden und entsprechende Modell-Wahrscheinlichkeit\n",
    "    p_stunden = modell_log.predict_proba([[stunden]])[0, 1]\n",
    "    plt.axvline(stunden, color=\"black\", linestyle=\"--\")\n",
    "    plt.scatter([stunden], [p_stunden], color=\"orange\", zorder=5, label=f\"dein Punkt ({stunden:.2f} h)\")\n",
    "    \n",
    "    plt.xlabel(\"Lernzeit in Stunden\")\n",
    "    plt.ylabel(\"p(bestanden)\")\n",
    "    plt.title(\"Logistische Regression: Wahrscheinlichkeit f√ºrs Bestehen\")\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"F√ºr {stunden:.2f} Stunden Lernzeit sch√§tzt das Modell:\")\n",
    "    print(f\"  p(bestanden) ‚âà {p_stunden*100:.1f} %\")\n",
    "    if p_stunden >= 0.5:\n",
    "        print(\"‚Üí Nach der 50%-Regel w√ºrde das Modell sagen: BESTANDEN.\")\n",
    "    else:\n",
    "        print(\"‚Üí Nach der 50%-Regel w√ºrde das Modell sagen: NICHT BESTANDEN.\")\n",
    "\n",
    "interact(\n",
    "    plot_logistic_with_point,\n",
    "    stunden=FloatSlider(value=2.5, min=0.0, max=5.0, step=0.1, description=\"Stunden\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee976c",
   "metadata": {},
   "source": [
    "## 5. Vorhersage mit dem Modell\n",
    "\n",
    "Wie bei der linearen Regression k√∂nnen wir eine **konkrete Frage** stellen:\n",
    "\n",
    "> ‚ÄûWas sagt das Modell f√ºr 3 Stunden Lernen?‚Äú\n",
    "\n",
    "Wir erhalten:\n",
    "- Eine **Wahrscheinlichkeit** zwischen 0 und 1\n",
    "- Eine Entscheidung (0 oder 1), wenn wir z. B. bei 50 % die Grenze ziehen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stunden = 3.0\n",
    "p_bestanden = modell_log.predict_proba([[stunden]])[0, 1]\n",
    "entscheidung = modell_log.predict([[stunden]])[0]\n",
    "\n",
    "print(f\"F√ºr {stunden} Stunden Lernzeit sch√§tzt das Modell:\")\n",
    "print(f\"  Wahrscheinlichkeit zu bestehen: {p_bestanden*100:.1f} %\")\n",
    "print(f\"  Modell-Entscheidung (0 = nicht bestanden, 1 = bestanden): {entscheidung}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6756a",
   "metadata": {},
   "source": [
    "## 6. Aufgaben\n",
    "\n",
    "Beantworte die folgenden Fragen **schriftlich** in einem separaten Dokument:\n",
    "\n",
    "1. **Beobachtung der Daten**\n",
    "   1. Schau dir den ersten Plot mit den 0/1-Punkten an.  \n",
    "      Wie ver√§ndert sich ungef√§hr der Anteil der ‚Äûbestanden‚Äú-Punkte, wenn die Lernzeit zunimmt?  \n",
    "   2. Ist der √úbergang eher abrupt (harte Grenze) oder weich (√úbergangsbereich)?\n",
    "\n",
    "2. **Entscheidungsgrenze in Stunden**\n",
    "   1. Spiele mit dem Schieberegler in der ersten interaktiven Grafik.  \n",
    "      Was passiert mit der Anzahl richtig klassifizierter Personen, wenn du die Grenze sehr tief setzt (z. B. 1 Stunde)?  \n",
    "   2. Was passiert, wenn du die Grenze sehr hoch setzt (z. B. 4.5 Stunden)?  \n",
    "   3. Beschreibe in eigenen Worten, warum eine **zu tiefe** oder **zu hohe** Grenze problematisch sein kann.\n",
    "\n",
    "3. **Wahrscheinlichkeit verstehen**\n",
    "   1. W√§hle in der zweiten interaktiven Grafik verschiedene Stundenwerte (z. B. 1 h, 2.5 h, 4 h).  \n",
    "      Wie ver√§ndert sich die gesch√§tzte Wahrscheinlichkeit, dass man besteht?  \n",
    "   2. Erkl√§re in einem Satz, was es bedeutet, wenn das Modell sagt:  \n",
    "      *‚Äûp(bestanden) = 0.8 f√ºr 3 Stunden Lernen‚Äú*.\n",
    "\n",
    "4. **Modell-Entscheidung**\n",
    "   1. Warum ist es sinnvoll, eine Grenze bei 50 % zu setzen (‚Äûab hier tippt das Modell auf bestanden‚Äú)?  \n",
    "   2. √úberlege dir eine Situation, in der man eine **strengere** Grenze w√§hlen w√ºrde (z. B. 70 %).\n",
    "\n",
    "5. **Vergleich zur linearen Regression**\n",
    "   1. Warum ist eine **lineare Regression** f√ºr Ja/Nein-Daten (0/1) nicht ideal?  \n",
    "   2. Nenne einen Vorteil der logistischen Regression im Vergleich zur linearen Regression in diesem Beispiel.\n",
    "6. **Kritische √úberlegung**\n",
    "   Nenne **zwei Gr√ºnde**, warum auch dieses Modell die Realit√§t nur **ungef√§hr** beschreibt.  \n",
    "   (Stichworte: andere Einfl√ºsse als Lernzeit, Zufall, Messfehler, ...)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
