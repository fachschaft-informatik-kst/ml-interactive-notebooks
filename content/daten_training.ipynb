{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1320d7d",
   "metadata": {},
   "source": [
    "\n",
    "# Daten fürs Training: Train / Validation / Test Split\n",
    "\n",
    "## Warum ist dieses Thema wichtig?\n",
    "\n",
    "Wenn du ein Modell mit Daten trainierst, ist es **nicht fair**, das Modell hinterher auf **denselben Daten** zu testen. \n",
    "Das wäre wie ein Schüler, der die Prüfungsfragen vorher kennt – natürlich macht er dann ein gutes Resultat!\n",
    "\n",
    "Damit ein Modell **wirklich gut** ist, muss es auch auf **neuen, unbekannten Daten** funktionieren.\n",
    "\n",
    "## Was lernst du in diesem Notebook?\n",
    "\n",
    "- **Warum** wir einen Datensatz aufteilen müssen\n",
    "- **Wie** man einen Datensatz in Train-, Validation- und Test-Set aufteilt\n",
    "- **Welche Rolle** jeder Teil spielt\n",
    "- **Interaktiv** sehen, wie die Aufteilung die Modellqualität beeinflusst\n",
    "\n",
    "> **Merksatz:**  \n",
    "> **Train-Set** = zum Lernen  \n",
    "> **Validation-Set** = zum Überprüfen während des Trainings  \n",
    "> **Test-Set** = zum finalen Testen (nur einmal am Schluss!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66f557",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Bibliotheken laden\n",
    "\n",
    "Wir verwenden hier nur:\n",
    "\n",
    "- `numpy` für Daten (Zahlen)\n",
    "- `matplotlib` für die Visualisierung\n",
    "- `ipywidgets` für die interaktiven Schieberegler\n",
    "\n",
    "In deiner JupyterLite-Umgebung sind diese Bibliotheken bereits installiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d659c",
   "metadata": {},
   "source": [
    "## 2. Beispiel-Datensatz: Iris-Klassifikation\n",
    "\n",
    "Wir nehmen den **Iris-Datensatz** aus scikit-learn mit nur **2 Features** (Sepal Length und Sepal Width):\n",
    "\n",
    "- Eingabe: 2D-Messwerte von Blütenkelchen\n",
    "- Ziel: Klassifikation der Iris-Art (3 Klassen)\n",
    "\n",
    "Mit nur 2 Features ist die Aufgabe schwieriger für Logistic Regression → \n",
    "man sieht besser, wie mehr Trainingsdaten helfen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a33535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Iris-Datensatz laden (nur 2 Features für bessere Visualisierung)\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]    # Nur Sepal Length und Sepal Width\n",
    "y = iris.target         # 3 Klassen\n",
    "\n",
    "n_samples = len(X)\n",
    "print(f\"Anzahl Datenpunkte insgesamt: {n_samples}\")\n",
    "print(f\"Features: {iris.feature_names[:2]}\")\n",
    "print(f\"Klassen: {iris.target_names} ({len(np.unique(y))} Klassen)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95096d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter-Plot der Iris-Daten nach Klasse gefärbt\n",
    "colors = ['#2ca02c', '#1f77b4', '#ff7f0e']\n",
    "for i, (label, color) in enumerate(zip(iris.target_names, colors)):\n",
    "    idx = y == i\n",
    "    ax.scatter(X[idx, 0], X[idx, 1], c=color, label=label, s=80, alpha=0.7, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(iris.feature_names[0], fontsize=11)\n",
    "ax.set_ylabel(iris.feature_names[1], fontsize=11)\n",
    "ax.set_title('Iris-Datensatz (2D)', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00013a52",
   "metadata": {},
   "source": [
    "### Die 3 Iris-Arten im Detail\n",
    "\n",
    "Der Iris-Datensatz enthält **3 verschiedene Arten** von Iris-Blüten:\n",
    "\n",
    "1. **Setosa** (grün) – Klein und kompakt\n",
    "2. **Versicolor** (blau) – Mittlere Größe\n",
    "3. **Virginica** (orange) – Groß und auffällig\n",
    "\n",
    "**Deine Aufgabe als ML-Modell:**  \n",
    "Schau auf die Sepal-Länge und -Breite → **Erkenne automatisch, welche Art das ist!**\n",
    "\n",
    "Das ist schwieriger als es klingt, weil sich die Arten teilweise überlappen (z.B. manche Versicolor und Virginica sind sich ähnlich)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ae6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jede Klasse einzeln visualisieren\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "colors = ['#2ca02c', '#1f77b4', '#ff7f0e']\n",
    "titles = ['Setosa (grün)', 'Versicolor (blau)', 'Virginica (orange)']\n",
    "\n",
    "for ax, i, color, title in zip(axes, range(3), colors, titles):\n",
    "    idx = y == i\n",
    "    ax.scatter(X[idx, 0], X[idx, 1], c=color, s=100, alpha=0.7, edgecolors='k', linewidth=1)\n",
    "    ax.set_xlabel(iris.feature_names[0], fontsize=11)\n",
    "    ax.set_ylabel(iris.feature_names[1], fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(4, 8.5)\n",
    "    ax.set_ylim(1.5, 4.5)\n",
    "\n",
    "plt.suptitle('Iris-Arten einzeln: Wie unterscheiden sie sich?', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiken für jede Klasse\n",
    "print(\"\\nStatistiken für jede Iris-Art:\")\n",
    "print(\"=\"*60)\n",
    "for i, name in enumerate(iris.target_names):\n",
    "    idx = y == i\n",
    "    print(f\"\\n{name.upper()} ({['grün', 'blau', 'orange'][i]}):\")\n",
    "    print(f\"  Anzahl: {np.sum(idx)} Blüten\")\n",
    "    print(f\"  Sepal Length: {X[idx, 0].min():.1f} - {X[idx, 0].max():.1f} cm (Ø {X[idx, 0].mean():.1f})\")\n",
    "    print(f\"  Sepal Width:  {X[idx, 1].min():.1f} - {X[idx, 1].max():.1f} cm (Ø {X[idx, 1].mean():.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8d7d4",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Interaktive Visualisierung von Train / Validation / Test\n",
    "\n",
    "### Die drei Sets erklärt:\n",
    "\n",
    "**Train-Set (grün):**\n",
    "- Das größte Set (z.B. 60% der Daten)\n",
    "- Wird benutzt, um das Modell zu **trainieren**\n",
    "- Das Modell \"sieht\" diese Daten und lernt daraus\n",
    "- **Ziel:** Die Parameter des Modells optimieren\n",
    "\n",
    "**Validation-Set (blau):**\n",
    "- Mittleres Set (z.B. 20% der Daten)\n",
    "- Wird während des Trainings benutzt, um das Modell zu **überprüfen**\n",
    "- Hilft dir, die beste **Version** des Modells zu finden (z.B. beste Hyperparameter)\n",
    "- **Wichtig:** Das Modell sieht diese Daten, aber du verwendest sie nicht zum Trainieren\n",
    "\n",
    "**Test-Set (orange):**\n",
    "- Kleinstes Set (z.B. 20% der Daten)\n",
    "- Wird **ganz am Schluss** verwendet - nur **einmal**!\n",
    "- Das Modell hat diese Daten **nie gesehen** während des Trainings\n",
    "- **Ziel:** Wirklich fair überprüfen: Funktioniert das Modell auf neuen Daten?\n",
    "\n",
    "### Wichtige Regel:\n",
    "⚠️ **Benutze das Test-Set niemals zum Trainieren oder zum Hyperparameter-Tuning!**  \n",
    "Wenn du das tust, ist dein Test nicht mehr fair – das Modell \"kennt\" die Testdaten schon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015143e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardisiere die Daten für bessere Visualisierung\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_2d = X_scaled  # Wir haben bereits 2D, also keine PCA nötig\n",
    "\n",
    "def split_indices(n_samples, train_frac=0.6, random_state=0):\n",
    "    '''Hilfsfunktion: erzeugt Indizes für Train / Val / Test mit festem Seed.''' \n",
    "    rng = np.random.default_rng(random_state)\n",
    "    indices = rng.permutation(n_samples)\n",
    "\n",
    "    # Größe der Splits berechnen\n",
    "    train_size = int(n_samples * train_frac)\n",
    "    remaining = n_samples - train_size\n",
    "\n",
    "    # Validation und Test bekommen je 50 % vom Rest\n",
    "    val_size = remaining // 2\n",
    "    test_size = remaining - val_size\n",
    "\n",
    "    train_idx = indices[:train_size]\n",
    "    val_idx = indices[train_size:train_size + val_size]\n",
    "    test_idx = indices[train_size + val_size:]\n",
    "\n",
    "    return train_idx, val_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_split(train_frac=0.6, random_state=0):\n",
    "    '''Visualisiert die Train / Val / Test Aufteilung als Scatter-Plot (Iris 2D-Daten).''' \n",
    "    train_idx, val_idx, test_idx = split_indices(\n",
    "        n_samples=len(X),\n",
    "        train_frac=train_frac,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    total = len(X)\n",
    "    train_size = len(train_idx)\n",
    "    val_size = len(val_idx)\n",
    "    test_size = len(test_idx)\n",
    "\n",
    "    train_pct = train_size / total * 100\n",
    "    val_pct = val_size / total * 100\n",
    "    test_pct = test_size / total * 100\n",
    "\n",
    "    # Scatter-Plot mit Iris-Daten\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Alle Daten grau im Hintergrund\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c='#dddddd', s=30, alpha=0.3, label='alle Daten')\n",
    "    \n",
    "    # Train-Daten (grün)\n",
    "    ax.scatter(X_2d[train_idx, 0], X_2d[train_idx, 1], c='#2ca02c', s=100, \n",
    "               edgecolors='k', linewidths=0.8, label=f'Train ({train_size})', alpha=0.8, marker='o')\n",
    "    \n",
    "    # Validation-Daten (blau)\n",
    "    ax.scatter(X_2d[val_idx, 0], X_2d[val_idx, 1], c='#1f77b4', s=100,\n",
    "               edgecolors='k', linewidths=0.8, label=f'Validation ({val_size})', alpha=0.8, marker='s')\n",
    "    \n",
    "    # Test-Daten (orange)\n",
    "    ax.scatter(X_2d[test_idx, 0], X_2d[test_idx, 1], c='#ff7f0e', s=100,\n",
    "               edgecolors='k', linewidths=0.8, label=f'Test ({test_size})', alpha=0.8, marker='^')\n",
    "    \n",
    "    ax.set_xlabel(iris.feature_names[0], fontsize=11)\n",
    "    ax.set_ylabel(iris.feature_names[1], fontsize=11)\n",
    "    ax.set_title(f'Train/Val/Test-Aufteilung (Train {int(train_frac*100)}%, Seed {random_state})', \n",
    "             fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Text-Ausgabe\n",
    "    print(f\"Train-Anteil: {int(train_frac*100)}% | Seed: {random_state}\")\n",
    "    print(f\"  Train:      {train_size:3d} ({train_pct:5.1f} %)\")\n",
    "    print(f\"  Validation: {val_size:3d} ({val_pct:5.1f} %)\")\n",
    "    print(f\"  Test:       {test_size:3d} ({test_pct:5.1f} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e113b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaktives Widget: mit Schieberegler spielen\n",
    "interact(\n",
    "    plot_split,\n",
    "    train_frac=widgets.FloatSlider(\n",
    "        value=0.6,\n",
    "        min=0.4,\n",
    "        max=0.8,\n",
    "        step=0.05,\n",
    "        description=\"Train-Anteil\"\n",
    "    ),\n",
    "    random_state=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        step=1,\n",
    "        description=\"Seed\"\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a315e00",
   "metadata": {},
   "source": [
    "## 4. Was ist Accuracy?\n",
    "\n",
    "**Accuracy** ist eine **Metrik** (=Messgröße), die misst, wie oft das Modell **richtig** vorhersagt.\n",
    "\n",
    "### Mathematische Definition:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{Anzahl richtige Vorhersagen}}{\\text{Anzahl alle Vorhersagen}} \\times 100\\%$$\n",
    "\n",
    "### Konkretes Beispiel:\n",
    "\n",
    "Stelle dir vor, dein Modell macht 50 Vorhersagen über Iris-Arten:\n",
    "- 40 Vorhersagen sind **richtig** ✓\n",
    "- 10 Vorhersagen sind **falsch** ✗\n",
    "\n",
    "Dann ist die **Accuracy = 40 / 50 = 0.8 = 80%**\n",
    "\n",
    "### Was bedeutet das?\n",
    "\n",
    "- **Accuracy = 100%** → Das Modell ist perfekt (sehr selten!)\n",
    "- **Accuracy = 80%** → Das Modell hat 8 von 10 Vorhersagen richtig\n",
    "- **Accuracy = 50%** → Das Modell ist nicht viel besser als raten\n",
    "- **Accuracy < 50%** → Das Modell ist schlecht\n",
    "\n",
    "### Wichtig:\n",
    "Wenn die **Test-Accuracy** deutlich **schlechter** ist als die **Train-Accuracy**, dann **überfitten** das Modell (es hat die Trainingsdaten zu gut auswendig gelernt, aber funktioniert nicht auf neuen Daten).\n",
    "\n",
    "## 5. Mini-Experiment: Iris-Klassifikation mit Logistischer Regression\n",
    "\n",
    "Wir trainieren eine **Logistische Regression** und sehen interaktiv, wie sich die Accuracy verändert, \n",
    "wenn wir den **Train-Anteil** variieren:\n",
    "\n",
    "- **Wenig Trainingsdaten** → das Modell hat nicht genug zum Lernen → schlechte Accuracy\n",
    "- **Mehr Trainingsdaten** → das Modell lernt besser → bessere Accuracy\n",
    "\n",
    "Die **Validation-Accuracy** zeigt, ob das Modell auf neuen Daten gut funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "def train_and_eval_digits(train_frac=0.6, random_state=0):\n",
    "    '''Trainiert LogisticRegression und zeigt Learning Curve (Accuracy vs. Train-Anteil).''' \n",
    "    train_idx, val_idx, test_idx = split_indices(len(X), train_frac=train_frac, random_state=random_state)\n",
    "\n",
    "    # Modell trainieren (nur auf Train-Set!)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "        model = LogisticRegression(max_iter=100, solver=\"lbfgs\", multi_class=\"auto\", random_state=random_state)\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "    # Vorhersagen\n",
    "    y_train_pred = model.predict(X[train_idx])\n",
    "    y_val_pred = model.predict(X[val_idx])\n",
    "    y_test_pred = model.predict(X[test_idx])\n",
    "\n",
    "    # Genauigkeiten\n",
    "    train_acc = accuracy_score(y[train_idx], y_train_pred)\n",
    "    val_acc = accuracy_score(y[val_idx], y_val_pred)\n",
    "    test_acc = accuracy_score(y[test_idx], y_test_pred)\n",
    "\n",
    "    # Plot: Accuracy vs. Train-Anteil (Learning Curve)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Linkes Plot: Accuracy für verschiedene Train-Anteile\n",
    "    train_fracs = np.linspace(0.1, 0.9, 9)\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "    # Ignoriere Warnung betreffend Konvergenz des Modells\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "        for tf in train_fracs:\n",
    "            ti, vi, te = split_indices(len(X), train_frac=tf, random_state=random_state)\n",
    "            m = LogisticRegression(max_iter=100, solver=\"lbfgs\", random_state=random_state)\n",
    "            m.fit(X[ti], y[ti])\n",
    "            train_accs.append(accuracy_score(y[ti], m.predict(X[ti])))\n",
    "            val_accs.append(accuracy_score(y[vi], m.predict(X[vi])))\n",
    "            test_accs.append(accuracy_score(y[te], m.predict(X[te])))\n",
    "\n",
    "    ax.plot(train_fracs * 100, train_accs, marker='o', label='Train-Accuracy', color='#2ca02c', linewidth=2.5, markersize=6)\n",
    "    ax.plot(train_fracs * 100, val_accs, marker='s', label='Validation-Accuracy', color='#1f77b4', linewidth=2.5, markersize=6)\n",
    "    ax.plot(train_fracs * 100, test_accs, marker='^', label='Test-Accuracy', color='#ff7f0e', linewidth=2.5, markersize=6)\n",
    "    ax.axvline(train_frac * 100, color='red', linestyle='--', linewidth=1.5, label=f'Aktueller Train-Anteil ({int(train_frac*100)}%)')\n",
    "    \n",
    "    ax.set_xlabel('Train-Anteil (%)', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_title('Wie viel Trainingsdaten brauchen wir?', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0.3, 1.05])\n",
    "    ax.set_xlim([5, 95])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Text-Ausgabe\n",
    "    print(f\"Train-Anteil: {int(train_frac*100)} % (Seed {random_state})\")\n",
    "    print(f\"  Train-Accuracy: {train_acc:.3f}  ({len(train_idx)} Beispiele)\")\n",
    "    print(f\"  Validation-Accuracy: {val_acc:.3f}  ({len(val_idx)} Beispiele)\")\n",
    "    print(f\"  Test-Accuracy:  {test_acc:.3f}  ({len(test_idx)} Beispiele)\")\n",
    "\n",
    "\n",
    "interact(\n",
    "    train_and_eval_digits,\n",
    "    train_frac=widgets.FloatSlider(\n",
    "        value=0.6,\n",
    "        min=0.1,\n",
    "        max=0.9,\n",
    "        step=0.1,\n",
    "        description=\"Train-Anteil\"\n",
    "    ),\n",
    "    random_state=widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=100,\n",
    "        step=1,\n",
    "        description=\"Seed\"\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5975d",
   "metadata": {},
   "source": [
    "## 6. Verständnisfragen\n",
    "\n",
    "Versuche, die folgenden MC-Fragen zu beantworten und zu erklären, warum deine Antwort richtig ist.\n",
    "\n",
    "### Frage 1: Das Problem mit dem Test-Set\n",
    "\n",
    "**Warum ist es problematisch, wenn man das Test-Set schon während des Trainings immer wieder verwendet?**\n",
    "\n",
    "a) Dann wird das Modell vielleicht schlechter.  \n",
    "b) Dann ist der Test nicht mehr fair, weil das Modell die Testdaten „kennt\". Die gemessene Genauigkeit ist zu optimistisch.  \n",
    "c) Es spielt keine Rolle – Hauptsache, die Accuracy ist hoch.\n",
    "\n",
    "**Erkläre:** Warum kann man das Test-Set nicht wiederholt benutzen?\n",
    "\n",
    "---\n",
    "\n",
    "### Frage 2: Wenig Trainingsdaten\n",
    "\n",
    "**Was passiert, wenn der Train-Anteil sehr klein ist (z.B. nur 20 %) und der Rest in Validation und Test geht?**\n",
    "\n",
    "a) Das Modell hat zu wenige Daten zum Lernen → schlechte Accuracy überall  \n",
    "b) Das Modell wird immer besser, weil wir mehr Testdaten haben.  \n",
    "c) Es ändert sich gar nichts.\n",
    "\n",
    "**Erkläre:** Wieso braucht ein Modell genug Trainingsdaten?\n",
    "\n",
    "---\n",
    "\n",
    "### Frage 3: Wozu Validation-Set?\n",
    "\n",
    "**Wozu braucht man überhaupt ein Validation-Set, wenn man schon ein Test-Set hat?**\n",
    "\n",
    "a) Validation-Set ist nur Deko und wird in der Praxis nie benutzt.  \n",
    "b) Man benutzt das Validation-Set, um **verschiedene Modelle/Einstellungen zu vergleichen**, ohne das Test-Set zu \"verunreinigen\".  \n",
    "c) Validation-Set und Test-Set sind genau dasselbe.\n",
    "\n",
    "**Erkläre:** Wann brauchst du das Validation-Set, und wann das Test-Set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
